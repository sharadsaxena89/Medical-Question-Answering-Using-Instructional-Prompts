{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "\n",
    "filename = '1.tsv'\n",
    "\n",
    "read_dir = 'C:\\\\Study Material\\\\Thesis\\\\Prompt_Tuning_v2\\\\Result_of_step_3'    \n",
    "read_path = read_dir + '\\\\' + filename  \n",
    "\n",
    "df = pd.read_csv(read_path, delimiter='\\t')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import linearized contents of table\n",
    "import json\n",
    "linearized_table_contents = []\n",
    "\n",
    "os.chdir(\"C:\\\\Study Material\\\\Thesis\\\\Prompt_Tuning_v2\")\n",
    "f = open('cleaned_symbol_tables_linearized_contents.json', 'r', errors=\"ignore\")\n",
    "json_object = json.load(f)\n",
    "for table_data in json_object:    \n",
    "    print(table_data['id'])\n",
    "    print(table_data['contents'])\n",
    "    linearized_table_contents.append(table_data['contents'])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_id = 0\n",
    "list_of_entries_duplicates_removed = []\n",
    "for row_id in range(0,len(df)):\n",
    "    answer_count = 1\n",
    "    if (not pd.isnull(df.iloc[row_id,3])):\n",
    "        answer_count = len (list(df.iloc[row_id,3].lstrip('[').rstrip(']').split(',')))\n",
    "    individual_row = list(df.iloc[row_id])\n",
    "    if (answer_count<6):\n",
    "        list_of_entries_duplicates_removed.append(individual_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_entries_duplicates_removed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_entries_with_context= []\n",
    "for individual_row in list_of_entries_duplicates_removed:\n",
    "    table_id = individual_row[0]\n",
    "    question = individual_row[1]\n",
    "    answer = individual_row[2]\n",
    "    list_of_tables = individual_row[3]\n",
    "    list_of_answers = individual_row[4]\n",
    "    \n",
    "    context = linearized_table_contents[int(table_id)-1]\n",
    "    if answer in context:\n",
    "        list_of_entries_with_context.append(individual_row)\n",
    "list_of_entries_with_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_of_entries_with_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '1.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the data to file\n",
    "\n",
    "random.seed(0)\n",
    "random.shuffle(list_of_entries_with_context)\n",
    "\n",
    "question_template_file_name = filename\n",
    "\n",
    "write_dir = \"C:\\\\Study Material\\\\Thesis\\\\Prompt_Tuning_v2\\\\Result_of_step_4\"\n",
    "\n",
    "path_write = write_dir + \"\\\\\" + question_template_file_name \n",
    "\n",
    "headerList = ['Table Id','Question','Answer','List of Tables','List of Answers']\n",
    "\n",
    "with open(path_write,\"w\", newline='', encoding='utf-8') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file, delimiter='\\t')\n",
    "\n",
    "    csv_writer.writerow(headerList)\n",
    "\n",
    "    for individual_row in list_of_entries_with_context:\n",
    "\n",
    "        csv_writer.writerow(individual_row)\n",
    "#                 print(individual_row)\n",
    "\n",
    "print(\"File successfully written: \",path_write)\n",
    "print(\"Number of questions\",len(list_of_entries_with_context))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.iloc[row_id,3].lstrip('[').rstrip(']').split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_count = len (list(df.iloc[row_id,3].lstrip('[').rstrip(']').split(',')))\n",
    "answer_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.iloc[row_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(filename):\n",
    "    read_dir = 'C:\\\\Study Material\\\\Thesis\\\\Prompt_Tuning_v2\\\\Result_of_step_3'    \n",
    "    read_path = read_dir + '\\\\' + filename \n",
    "    df = pd.read_csv(read_path, delimiter='\\t')\n",
    "    list_of_entries_duplicates_removed = []\n",
    "    for row_id in range(0,len(df)):\n",
    "        answer_count = 1\n",
    "        if (not pd.isnull(df.iloc[row_id,3])):\n",
    "            answer_count = len (list(df.iloc[row_id,3].lstrip('[').rstrip(']').split(',')))\n",
    "        individual_row = list(df.iloc[row_id])\n",
    "        if (answer_count<6):\n",
    "            list_of_entries_duplicates_removed.append(individual_row)\n",
    "    list_of_entries_with_context= []\n",
    "    for individual_row in list_of_entries_duplicates_removed:\n",
    "        table_id = individual_row[0]\n",
    "        question = individual_row[1]\n",
    "        answer = individual_row[2]\n",
    "        list_of_tables = individual_row[3]\n",
    "        list_of_answers = individual_row[4]\n",
    "\n",
    "        context = linearized_table_contents[int(table_id)-1]\n",
    "        if answer in context:\n",
    "            list_of_entries_with_context.append(individual_row)\n",
    "            \n",
    "    random.seed(0)\n",
    "    random.shuffle(list_of_entries_with_context)\n",
    "\n",
    "    question_template_file_name = filename\n",
    "\n",
    "    write_dir = \"C:\\\\Study Material\\\\Thesis\\\\Prompt_Tuning_v2\\\\Result_of_step_4\"\n",
    "\n",
    "    path_write = write_dir + \"\\\\\" + question_template_file_name \n",
    "\n",
    "    headerList = ['Table Id','Question','Answer','List of Tables','List of Answers']\n",
    "\n",
    "    with open(path_write,\"w\", newline='', encoding='utf-8') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file, delimiter='\\t')\n",
    "\n",
    "        csv_writer.writerow(headerList)\n",
    "\n",
    "        for individual_row in list_of_entries_with_context:\n",
    "\n",
    "            csv_writer.writerow(individual_row)\n",
    "    #                 print(individual_row)\n",
    "\n",
    "    print(\"File successfully written: \",path_write)\n",
    "    print(\"Number of questions\",len(list_of_entries_with_context))  \n",
    "\n",
    "generate(\"1.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,23):\n",
    "    filename = str(i)+'.tsv'\n",
    "    generate(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
