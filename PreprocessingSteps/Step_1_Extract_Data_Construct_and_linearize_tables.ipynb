{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "os.chdir(\"C:\\\\Study Material\\\\Thesis\\\\Prompt_Tuning_v2\\\\Tables_with_3_rows\")\n",
    "df = pd.read_csv(\"1.tsv\", delimiter='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_rows = []\n",
    "read_dir = \"C:\\\\Study Material\\\\Thesis\\\\Prompt_Tuning_v2\\\\Tables_with_3_rows\"\n",
    "for filename in range(1,343):\n",
    "    read_path = read_dir + \"\\\\\" + str(filename) + \".tsv\"\n",
    "    df = pd.read_csv(read_path, delimiter='\\t')\n",
    "    for row_id in range(0,len(df)):\n",
    "        individual_row = [df.iloc[row_id,0],df.iloc[row_id,1],df.iloc[row_id,2],df.iloc[row_id,3],df.iloc[row_id,4]]\n",
    "        list_of_rows.append(individual_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_of_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dir = \"C:\\\\Study Material\\\\Thesis\\\\Prompt_Tuning_v2\\\\Final_tables_with_2_rows\"\n",
    "current_filename = 0\n",
    "for i in range(0,len(list_of_rows),2):\n",
    "    current_index = i\n",
    "    current_filename+=1\n",
    "    path_write = write_dir + \"\\\\\" + str(current_filename) + \".tsv\"\n",
    "    with open(path_write,\"w\", newline='', encoding='utf-8') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file, delimiter='\\t')\n",
    "        individual_row = ['Disease','Background','Key Symptoms','Key Signs','Additional information']\n",
    "        csv_writer.writerow(individual_row)\n",
    "        \n",
    "        individual_row = list_of_rows[current_index]\n",
    "        csv_writer.writerow(individual_row)\n",
    "        \n",
    "        individual_row = list_of_rows[current_index+1]\n",
    "        csv_writer.writerow(individual_row)      \n",
    "        \n",
    "        \n",
    "# Ignore error, tables are being created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to linearize table\n",
    "import os\n",
    "\n",
    "def convert_table_to_linearized(path_read):\n",
    "#     table_to_linearize = pd.read_csv(path_read,encoding='utf-8',warn_bad_lines=True, error_bad_lines=False)\n",
    "    table_to_linearize = pd.read_csv(path_read,encoding='utf-8', delimiter='\\t')\n",
    "    list_of_columns = table_to_linearize.columns\n",
    "#     table_to_linearize = pd.read_csv(path_read,encoding='utf-8')\n",
    "    number_of_rows = table_to_linearize.shape[0]\n",
    "    number_of_columns = table_to_linearize.shape[1]\n",
    "    linearized_table = ''\n",
    "    for i in range(0,number_of_rows):\n",
    "        linearized_table+= 'Row '+str(i+1)+' is : '\n",
    "        for j in range(0,number_of_columns):\n",
    "            linearized_table+= str(table_to_linearize.columns[j]).strip()+' is : '+str(table_to_linearize.iloc[i,j]).strip()\n",
    "            if number_of_rows>0 and j<(number_of_columns - 1) :\n",
    "               linearized_table+= ' ; ' \n",
    "        linearized_table+= '. '\n",
    "    return linearized_table\n",
    "\n",
    "os.chdir(\"C:\\\\Study Material\\\\Thesis\\\\Prompt_Tuning_v2\\\\Final_tables_with_2_rows\")\n",
    "\n",
    "read_dir = os.getcwd()\n",
    "path_read = read_dir +\"\\\\\"+ \"1.tsv\"  \n",
    "a = convert_table_to_linearized(path_read)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_table_folder_paths =[]\n",
    "table_directory = (\"C:\\\\Study Material\\\\Thesis\\\\Prompt_Tuning_v2\\\\Final_tables_with_2_rows\\\\\")\n",
    "for i in range(1,514):\n",
    "    table_path = table_directory + str(i) + \".tsv\"\n",
    "    list_of_table_folder_paths.append(table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_linearized_tables = []\n",
    "for i in range(0,513):    \n",
    "    try: \n",
    "        linearized_table = convert_table_to_linearized(list_of_table_folder_paths[i])\n",
    "        print(i,\" Successfully linearized the table: \",list_of_table_folder_paths[i]) \n",
    "        list_of_linearized_tables.append(linearized_table)\n",
    "    except Exception as e:\n",
    "        print(\"Skipping table:\", list_of_table_folder_paths[i])\n",
    "        print(\"Exception:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Study Material\\\\Thesis\\\\Prompt_Tuning_v2\")\n",
    "import json\n",
    "linearized_tables_in_pre_json_format = []\n",
    "for i in range(0,len(list_of_linearized_tables)):\n",
    "     linearized_tables_in_pre_json_format.append({\n",
    "    'id': (i+1),\n",
    "    'contents': list_of_linearized_tables[i]\n",
    "    })\n",
    "\n",
    "with open('symbol_tables_linearized_contents.json', 'w') as outfile:\n",
    "    json.dump(linearized_tables_in_pre_json_format,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CLEANED linearized contents of table\n",
    "import json\n",
    "linearized_table_contents = []\n",
    "\n",
    "os.chdir(\"C:\\\\Study Material\\\\Thesis\\\\Prompt_Tuning_v2\")\n",
    "f = open('cleaned_symbol_tables_linearized_contents.json', 'r', errors=\"ignore\")\n",
    "json_object = json.load(f)\n",
    "for table_data in json_object:    \n",
    "    print(table_data['id'])\n",
    "    print(table_data['contents'])\n",
    "    linearized_table_contents.append(table_data['contents'])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "average = 0\n",
    "total =0\n",
    "count=0\n",
    "max_len = 0\n",
    "for table_id in range(0,len(linearized_table_contents)):\n",
    "    tokens = tokenizer(linearized_table_contents[table_id])\n",
    "    print(len(tokens['input_ids']))\n",
    "    average+=len(tokens['input_ids'])\n",
    "    total+=1\n",
    "    if (len(tokens['input_ids'])<512):\n",
    "        count+=1\n",
    "    else:\n",
    "        print('Table: ',(table_id+1),' token count: ',len(tokens['input_ids']))\n",
    "    if (max_len<len(tokens['input_ids'])):\n",
    "        max_len = len(tokens['input_ids'])\n",
    "        \n",
    "average= average/total\n",
    "print('Average: ',average)\n",
    "print('Count of tables less than 512: ',count)\n",
    "print('max_len: ',max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(linearized_table_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
